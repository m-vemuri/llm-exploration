{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "886a98a5-3223-4144-899d-88b48a00a848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import minsearch\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c5af415-c001-4a08-a7d5-49682bab7c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('documents.json', 'rt') as f_in:\n",
    "    documents_raw = json.load(f_in)\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2e917e-3508-4631-a8bf-1f6c8017fd35",
   "metadata": {},
   "source": [
    "# using Elastic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bfcecf4-7f88-41e7-913e-a8d47e9c5289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d331cae6bed448393438448611ec933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/948 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "\n",
    "es_client = Elasticsearch('http://localhost:9200') \n",
    "\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"} \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"course-questions\"\n",
    "\n",
    "es_client.indices.create(index=index_name, body=index_settings)\n",
    "\n",
    "for doc in tqdm(documents):\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6cbe1c2-23b5-4f1f-bde6-2836362edbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = OpenAI(\n",
    "#     api_key=os.environ.get(\"OPEN_API_KEY\"),\n",
    "# )\n",
    "\n",
    "\n",
    "# for ollama\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "    api_key='ollama',\n",
    ")\n",
    "\n",
    "def search(query):\n",
    "    boost = {'question': 3.0, 'text': 0.5}\n",
    "    filter_dict = {'course': 'data-engineering-zoomcamp'}\n",
    "    \n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict=filter_dict,\n",
    "        boost_dict=boost,\n",
    "        num_results=11\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "def get_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "    You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ table.\n",
    "    Answer the QUESTION only using facts from the CONTEXT. \n",
    "    If you cannot answer the QUESTION using the CONTEXT, return NONE.\n",
    "    \n",
    "    QUESTION: {question}\n",
    "    \n",
    "    CONTEXT: {context}\n",
    "    \"\"\".strip()\n",
    "\n",
    "\n",
    "    context = \"\"\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "\n",
    "    return prompt_template.format(question=query, context=context.strip()).strip()\n",
    "\n",
    "\n",
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\", \n",
    "        messages=[{\"role\":\"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def llm_ollama(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"phi3\", \n",
    "        messages=[{\"role\":\"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b499419-98b2-4f12-b6e4-b5b8f97d5bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def elastic_search(query):\n",
    "    search_query = {\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^3\", \"text\", \"section\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"course\": \"data-engineering-zoomcamp\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = es_client.search(index=index_name, body=search_query)\n",
    "    \n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in response['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "    \n",
    "    return result_docs\n",
    "\n",
    "\n",
    "def rag(query):\n",
    "    search_results = elastic_search(query)\n",
    "    prompt = get_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer\n",
    "\n",
    "\n",
    "\n",
    "def rag_ollama(query):\n",
    "    search_results = elastic_search(query)\n",
    "    prompt = get_prompt(query, search_results)\n",
    "    answer = llm_ollama(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "124de10e-7094-475a-a1b0-16ba3a92f3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Yes, you are still eligible to submit the course assignments even after the official start date of the Course - General Data Engineering Bootcamp has passed your way by email as there's no strict registration deadline mentioned in the provided context for receiving confirmation emails post-start date; however, be mindful that final projects have submission deadlines.\n"
     ]
    }
   ],
   "source": [
    "query = 'I just disovered the course. Can I still join it?'\n",
    "\n",
    "\n",
    "# rag(query)\n",
    "output = rag_ollama(query)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75d5c0e-5fd3-406a-bd49-ba15d8fcad2e",
   "metadata": {},
   "source": [
    "# Homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf3990ed-babb-44ba-951e-d4fa260ba3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "    api_key='ollama'\n",
    ")\n",
    "\n",
    "\n",
    "def llm_ollama(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gemma:2b\", \n",
    "        messages=[{\"role\":\"user\", \"content\": prompt}],\n",
    "        temperature=0.0\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "prompt = \"What's the formula for energy?\"\n",
    "\n",
    "output = llm_ollama(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbb47390-1d71-4b5a-91e3-21d8bc66f671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here's the formula for energy:\n",
      "\n",
      "**E = K + U**\n",
      "\n",
      "Where:\n",
      "\n",
      "* **E** is the energy in joules (J)\n",
      "* **K** is the kinetic energy in joules (J)\n",
      "* **U** is the potential energy in joules (J)\n",
      "\n",
      "**Kinetic energy (K)** is the energy an object possesses when it moves or is in motion. It is calculated as half the product of an object's mass (m) and its velocity (v) squared:\n",
      "\n",
      "**K = 1/2mv^2**\n",
      "\n",
      "**Potential energy (U)** is the energy an object possesses due to its position or configuration. It is calculated as the product of an object's mass, gravitational constant (g), and height or position above a reference point.\n",
      "\n",
      "**U = mgh**\n",
      "\n",
      "Where:\n",
      "\n",
      "* **m** is the mass in kilograms (kg)\n",
      "* **g** is the gravitational constant (9.8 m/s^2)\n",
      "* **h** is the height or position in meters (m)\n",
      "\n",
      "The formula shows that energy can be expressed as the sum of kinetic and potential energy. The kinetic energy is a measure of the object's ability to do work, while the potential energy is a measure of the object's ability to do work against a force.\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de99a77b-99bd-4a16-9b5f-559738036931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /Users/talldarkandhandsome/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "280"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "from huggingface_hub import login\n",
    "import os\n",
    "\n",
    "login(os.environ['HF_TOKEN'])\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2b\")\n",
    "\n",
    "output_ids = tokenizer.tokenize(output)\n",
    "len(output_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7f2223-5991-4d32-ab8b-32bc0c74405b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
